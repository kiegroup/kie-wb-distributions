<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0" xml:base="." xml:id="wb.DataSets"
  xsi:schemaLocation="http://docbook.org/ns/docbook http://www.docbook.org/xml/5.0/xsd/docbook.xsd http://www.w3.org/1999/xlink http://www.docbook.org/xml/5.0/xsd/xlink.xsd"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns:xs="http://www.w3.org/2001/XMLSchema"
  xmlns:xlink="http://www.w3.org/1999/xlink"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:ns="http://docbook.org/ns/docbook">

  <title>Data Sets</title>

  <!--
   - Backend deploy directory
   - GIT Storage
  -->

  <para>A <emphasis role="bold">data set</emphasis> is basically a set of columns populated with some rows, a matrix of data composed of timestamps, texts and numbers.
    A data set can be stored in different systems: a database, an excel file, in memory or in a lot of other different systems. On the other hand, a
    <emphasis role="bold">data set definition</emphasis> tells the workbench modules how such data can be accessed, read and parsed.
  </para>

  <para>
    Notice, it's very important to make crystal clear the difference between a data set and its definition since the workbench does not take care of storing any data,
    it just provides an standard way to define access to those data sets regardless where the data is stored.
  </para>

  <para>Let's take for instance the data stored in a remote database. A valid data set could be, for example, an entire database table or the result of an SQL query.
    In both cases, the database will return a bunch of columns and rows. Now, imagine we want to get access to such data to feed some charts in a new workbench perspective.
    First thing is to create and register a data set definition in order to indicate the following:
  </para>

  <itemizedlist>
    <listitem>
      <para>where the data set is stored,</para>
    </listitem>
    <listitem>
      <para>how can be accessed, read and parsed and</para>
    </listitem>
    <listitem>
      <para>what columns contains and of which type.</para>
    </listitem>
  </itemizedlist>

  <para>
    This chapter introduces the available workbench tools for registering and handling data set definitions and how this definitions can be consumed in other workbench modules
    like, for instance, the Perspective Editor.
  </para>

  <note>
    <para>
      For simplicity sake we will be using the term <emphasis>data set</emphasis> to refer to the actual data set definitions as <emphasis>Data set</emphasis> and
      <emphasis>Data set definition</emphasis> can be considered synonyms under the data set authoring context.
    </para>
  </note>

  <section xml:id="wb.DataSetAuthoringPerspective">
    <title>Data Set Authoring Perspective</title>

    <para>Everything related to the authoring of data sets can be found under the <emphasis>Data Set Authoring</emphasis> perspective which
      is accessible from the following top level menu entry: <emphasis>Extensions>Data Sets</emphasis>, as shown in the following screenshot.</para>

    <figure>
      <title>Data Set Authoring Perspective</title>
      <screenshot>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetAuthoringPerspective.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </screenshot>
    </figure>

    <para>
      The center panel, shows a welcome screen, whilst the left panel contains the <emphasis>Data Set Explorer</emphasis> listing all the data
      sets available
    </para>

    <note>
      <para>
        This perspective is only intended to Administrator users, since defining data sets can be considered a low level task.
      </para>
    </note>
  </section>

  <section xml:id="wb.DataSetExplorer">
    <title>Data Set Explorer</title>

    <para>
      The <emphasis>Data Set Explorer</emphasis> list the data sets present in the system. Every time the user clicks on the data set it shows a brief summary alongside the
      following information:
    </para>

    <figure>
      <title>Data Set Explorer</title>
      <screenshot>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetExplorer.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </screenshot>
    </figure>

    <itemizedlist>
      <listitem>
        <para>(1) A button for creating a new Data set</para>
      </listitem>
      <listitem>
        <para>(2) The list of currently available Data sets</para>
      </listitem>
      <listitem>
        <para>(3) An icon that represents the Data set's provider type (Bean, SQL, CSV, etc)</para>
      </listitem>
      <listitem>
        <para>(4) Details of current cache and refresh policy status</para>
      </listitem>
      <listitem>
        <para>(5) Details of current size on backend (unit as rows) and current size on client side (unit in bytes)</para>
      </listitem>
      <listitem>
        <para>(6) The button for editing the Data set. Once clicked the Data set editor screen is opened on the center panel</para>
      </listitem>
    </itemizedlist>

    <para>
      The next sections explains how to create, edit and fine tune data set definitions.
    </para>

  </section>

  <!-- Advanced settings -->

  <section xml:id="wb.DataSetCreation">
    <title>Data Set Creation</title>

    <para>
      Clicking on the <emphasis>New Data Set</emphasis> button opens a new screen from which the user is
      able to create a new data set definition in three steps:
    </para>

    <itemizedlist>
      <listitem>
        <para>
          <emphasis>Provider type selection</emphasis>
          <para>
            Specify the kind of the remote storage system (BEAN, SQL, CSV, ElasticSearch)
          </para>
        </para>

      </listitem>
      <listitem>
        <para>
          <emphasis>Provider configuration</emphasis>
          <para>
            Specify the attributes for being able to look up data from the remote system.
            The configuration varies depending on the data provider type selected.
          </para>
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis>Data set columns &amp; filter</emphasis>
          <para>
            Live data preview, column types and initial filter configuration.
          </para>
        </para>
      </listitem>
    </itemizedlist>

    <section xml:id="wb.DataSetCreationTypeSelection">
      <title>Step 1: Provider type selection</title>

      <para>
        Allows the user's specify the type of data provider of the data set being created.
      </para>
      <para>
        This screen lists all the current available data provider types and helper popovers with descriptions. Each data provider is represented with a descriptive image:
      </para>

      <figure>
        <title>Provider type selection</title>
        <screenshot>
          <mediaobject>
            <imageobject>
              <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetDefTypeSelection.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </screenshot>
      </figure>

      <para>
        Four types are currently supported:
      </para>

      <itemizedlist>
        <listitem>
          <para>Bean (Java class) - To generate a data set directly from Java</para>
        </listitem>
        <listitem>
          <para>SQL - For getting data from any ANSI-SQL compliant database</para>
        </listitem>
        <listitem>
          <para>CSV - To upload the contents of a remote or local CSV file</para>
        </listitem>
        <listitem>
          <para>Elastic Search - To query and get documents stored on Elastic Search nodes as data sets</para>
        </listitem>
      </itemizedlist>

      <para>
        Once a type is selected, click on Next button to continue with the next workflow step.
      </para>
    </section>

    <section xml:id="wb.DataSetCreationConfiguration">
      <title>Step 2: Configuration</title>

      The screenshot below shows a CSV data set configuration form. Once all the required settings are filled
      click on Test button. The system will try to fetch an small amount of data before moving to the next workflow step.

      <figure>
        <title>CSV Configuration</title>
        <screenshot>
          <mediaobject>
            <imageobject>
              <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetDefConfigScreen.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </screenshot>
      </figure>

      <para>
      The provider type selected in the previous step will determine which configuration settings the system asks for.
      </para>

      <figure>
        <title>Configuration screen per data set type</title>
        <screenshot>
          <mediaobject>
            <imageobject>
              <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetDefConfigTypes.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </screenshot>
      </figure>

      <note>
        <para>
          The UUID attribute is a read only field as it's generated by the system. It's only intended for usage in API calls or specific operations.
        </para>
      </note>
    </section>

    <section xml:id="wb.DataSetCreationPreview">
      <title>Step 3: Data set columns and preview</title>

      <para>
        After clicking on the <emphasis>Test</emphasis> button (see previous step), the system executes a data set
        lookup test call in order to check if the remote system is up and the data is available. If everything goes ok
        the user will see the following screen:
      </para>

      <figure>
        <title>Data set preview</title>
        <screenshot>
          <mediaobject>
            <imageobject>
              <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetDefLivePreview.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </screenshot>
      </figure>

      <para>
        This screen shows a live data preview along with the columns the user wants to be part of the resulting data set. The user can also navigate through
        the data and apply some changes to the data set structure. Once finished, we can click on the <emphasis>Save</emphasis> button in order
        to register the new data set definition.
      </para>

      <para>
        We can also change the configuration settings at any time just by going back to the configuration tab. We can repeat the
        <emphasis>Configuration>Test>Preview</emphasis> cycle as may times as needed until we consider it's ready to be saved.
      </para>

      <!-- Data set columns -->

      <para>
        <emphasis role="bold">Columns</emphasis>
      </para>

      <para>
        In the <emphasis>Columns</emphasis> tab area the user can select what columns are part of the resulting data set definition.
      </para>

      <figure>
        <title>Data set columns</title>
        <screenshot>
          <mediaobject>
            <imageobject>
              <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetDefColumns.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </screenshot>
      </figure>

      <itemizedlist>
        <listitem>
          <para>
            (1) To add or remove columns. Select only those columns you want to be part of the resulting data set
          </para>
        </listitem>
        <listitem>
          <para>
            (2) Use the drop down image selector to change the column type
          </para>
        </listitem>
      </itemizedlist>

      <para>
        A data set may only contain columns of any of the following 4 types:
      </para>

      <itemizedlist>
        <listitem>
          <para>
            Label - For text values supporting group operations (similar to the SQL "group by" operator) which means you can perform data lookup calls and get one row per distinct value.
          </para>
        </listitem>
        <listitem>
          <para>
            Text - For text values NOT supporting group operations. Typically for modeling large text columns such as abstracts, descriptions and the like.
          </para>
        </listitem>
        <listitem>
          <para>
            Number - For numeric values. It does support aggregation functions on data lookup calls: sum, min, max, average, count, disctinct.
          </para>
        </listitem>
        <listitem>
          <para>
            Date - For date or timestamp values. It does support time based group operations by different time intervals: minute, hour, day, month, year, ...
          </para>
        </listitem>
      </itemizedlist>

      <para>
        No matter which remote system you want to retrieve data from, the resulting data set will always return a set of columns of one of the four types above.
        There exists, by default, a mapping between the remote system column types and the data set types. The user is able to modify the type for some columns, depending
        on the data provider and the column type of the remote system. The system supports the following changes to column types:
      </para>

      <itemizedlist>
        <listitem>
          <para>
            Label &lt;&gt; Text - Useful when we want to enable/disable the categorization (grouping) for the target column. For instance, imagine a database table called
            "document" containing a large text column called "abstract". As we do not want the system to treat such column as a "label" we might change its column type to "text".
            Doing so, we are optimizing the way the system handles the data set and
          </para>
        </listitem>
        <listitem>
          <para>
            Number &lt;&gt; Label - Useful when we want to treat numeric columns as labels. This can be used for instance to indicate that a given numeric column is not a numeric
            value that can be used in aggregation functions. Despite its values are stored as numbers we want to handle the column as a "label". One example of such columns are:
            an item's code, an appraisal id., ...
          </para>
        </listitem>
      </itemizedlist>

      <note>
        <para>
          BEAN data sets do not support changing column types as it's up to the developer to decide which are the concrete types for each column.
        </para>
      </note>

      <!-- Data set filter -->

      <para>
        <emphasis role="bold">Filter</emphasis>
      </para>

      <para>
        A data set definition may define a filter. The goal of the filter is to leave out rows the user does not consider necessary. The filter feature works on any data provider type
        and it lets the user to apply filter operations on any of the data set columns available.
      </para>

      <figure>
        <title>Data set filter</title>
        <screenshot>
          <mediaobject>
            <imageobject>
              <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetDefFilter.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </screenshot>
      </figure>

      <para>
        While adding or removing filter conditions and operations, the preview table on central area is updated with live data that reflects the current filter status.
      </para>

      <para>
        There exists two strategies for filtering data sets and it's also important to note that choosing between the two have important implications. Imagine a dashboard
        with some charts feeding from a expense reports data set where such data set is built on top of an SQL table. Imagine also we only want to retrieve the
        expense reports from the "London" office. You may define a data set containing the filter "office=London" and then having several charts feeding from
        such data set. This is the recommended approach. Another option is to define a data set with no initial filter and then let the individual charts to specify their own filter.
        It's up to the user to decide on the best approach.
      </para>

      <para>
        Depending on the case it might be better to define the filter at a data set level for reusing across other modules. The decision may also have impact on the performance
        since a filtered cached data set will have far better performance than a lot of individual non-cached data set lookup requests. (See the next section for more information about
        caching data sets).
      </para>

      <note>
        <para>
          Notice, for SQL data sets, the user can use both the filter feature introduced or, alternatively, just add custom filter criteria to the SQL sentence. Although, the first
          approach is more appropriated for non technical users since they might not have the required SQL language skills.
        </para>
      </note>
    </section>

  </section>

  <!-- Data set edition -->

  <section xml:id="wb.DataSetDefEditor">
    <title>Data set editor</title>

    <para>
      To edit an existing data set definition go the data set explorer, expand the desired data set definition and click on the <emphasis>Edit</emphasis> button.
      This will cause a new editor panel to be opened and placed on the center of the screen, as shown in the next screenshot:
    </para>

    <figure>
      <title>Data set definition editor</title>
      <screenshot>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetDefEditor.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </screenshot>
    </figure>

    Every time we edit an item its editor is added to the center panel. We can navigate through the list of opened editors just by clicking on the down arrow icon placed at the
    editor's toolbar in the top right corner.

    <figure>
      <title>Editor selector</title>
      <screenshot>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetDefEditorSelector.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </screenshot>
    </figure>

    The editor provides all the features described in previous sections. We can change the configuration settings, test our data set definition and modify the resulting data set
    structure. Additionally, the editor provides some extra buttons in its toolbar:

    <itemizedlist>
      <listitem>
        <para>
          Save - To validate the current changes and store the data set definition.
        </para>
      </listitem>
      <listitem>
        <para>
          Delete - To remove permanently from storage the data set definition. Any client module referencing the data set may be affected.
        </para>
      </listitem>
      <listitem>
        <para>
          Validate - To check that all the required parameters exists and are correct, as well as to validate the data set can be retrieved with no issues.
        </para>
      </listitem>
      <listitem>
        <para>
          Copy - To create a brand new definition as a copy of the current one.
        </para>
      </listitem>
    </itemizedlist>

    <note>
      <para>
        Data set definitions are stored in the underlying GIT repository as JSON files. Any action performed is registered in the repository logs so it is possible to audit
        the change log later on.
      </para>
    </note>
  </section>

  <!-- Advanced settings -->

  <section xml:id="wb.DataSetAdvancedSettings">
    <title>Advanced settings</title>

    <para>
      In the <emphasis>Advanced settings</emphasis> tab area the user can specify caching and refresh settings. Those are very important for making the most of the system capabilities
      thus improving the performance and having better application responsive levels.
    </para>

    <figure>
      <title>Advanced settings</title>
      <screenshot>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetDefAdvanced.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </screenshot>
    </figure>

    <itemizedlist>
      <listitem>
        <para>
          (1) To enable or disable the client cache and specify the maximum size (bytes).
        </para>
      </listitem>
      <listitem>
        <para>
          (2) To enable or disable the backend cache and specify the maximum cache size (number of rows).
        </para>
      </listitem>
      <listitem>
        <para>
          (3) To enable or disable automatic refresh for the Data set and the refresh period.
        </para>
      </listitem>
      <listitem>
        <para>
          (4) To enable or disable the refresh on stale data setting.
        </para>
      </listitem>
    </itemizedlist>

    <para>
      Let's dig into more details about the meaning of these settings.
    </para>

  </section>

  <!-- Caching -->

  <section xml:id="wb.DataSetCacheSettings">
    <title>Caching</title>

    <para>
      The system provides caching mechanisms out-of-the-box for holding data sets and performing data operations using in-memory strategies. The use of these features brings a lot of
      advantages, like reducing the network traffic, remote system payload, processing times etc. On the other hand, it's up to the user to fine tune properly the caching settings
      to avoid hitting performance issues.
    </para>

    <para>
      Two cache levels are supported:
    </para>

    <itemizedlist>
      <listitem>
        <para>
          Client level
        </para>
      </listitem>
      <listitem>
        <para>
          Backend level
        </para>
      </listitem>
    </itemizedlist>

    <para>
      The following diagram shows how caching is involved in any data set operation:
    </para>

    <figure>
      <title>Data set caching</title>
      <screenshot>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetCacheArchitecture.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </screenshot>
    </figure>

    <para>
      Any data look up call produces a resulting data set, so the use of the caching techniques determines where the data lookup calls are executed and where the resulting data set is
      located.
    </para>

    <!-- Client cache -->

    <para>
      <emphasis role="bold">Client cache</emphasis>
    </para>

    <para>
      If ON then the data set involved in a look up operation is pushed into the web browser so that all the components that feed from this data set
      <emphasis role="bold">do not need to perform any requests to the backend</emphasis> since data set operations are resolved at a client side:
    </para>

    <itemizedlist>
      <listitem>
        <para>
          The data set is stored in the web browser's memory
        </para>
      </listitem>
      <listitem>
        <para>
          The client components feed from the data set stored in the browser
        </para>
      </listitem>
      <listitem>
        <para>
          Data set operations (grouping, aggregations, filters and sort) are processed within the web browser, by means of a Javascript data set operation engine.
        </para>
      </listitem>
    </itemizedlist>

    <para>
      If you know beforehand that your data set will remain small, you can enable the client cache. It will reduce the number of backend requests, including the requests to
      the storage system.  On the other hand, if you consider that your data set will be quite big, disable the client cache so as to not hitting with browser issues such as slow
      performance or intermittent hangs.
    </para>

    <!-- Backend cache -->

    <para>
      <emphasis role="bold">Backend cache</emphasis>
    </para>

    <para>
      Its goal is to provide a caching mechanism for data sets on backend side.
    </para>

    <para>
      This feature allows to <emphasis role="bold">reduce the number of requests to the remote storage system</emphasis> , by holding the data set in memory and performing group,
      filter and sort operations using the in-memory engine.
    </para>

    <para>It's useful for data sets that do not change very often and their size can be considered acceptable to be held and processed in memory. It can be also helpful on low latency
      connectivity issues with the remote storage. On the other hand, if your data set is going to be updated frequently, it's better to disable the backend cache and perform the
      requests to the remote storage on each look up request, so the storage system is in charge of resolving the data set lookup request.</para>

    <note>
      <para>
        BEAN and CSV data providers relies by default on the backend cache, as in both cases the data set must be always loaded into memory in order to resolve any data lookup operation
        using the in-memory engine. This is the reason why the backend settings are not visible in the Advanced settings tab.
      </para>
    </note>

  </section>

  <!-- Refresh settings -->

  <section xml:id="wb.DataSetRefreshSettings">
    <title>Refresh</title>

    <para>
      The refresh feature allows for the invalidation of any cached data when certain conditions are meet.
    </para>

    <figure>
      <title>Refresh settings</title>
      <screenshot>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/Workbench/Authoring/DataSets/DataSetDefRefreshSettings.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </screenshot>
    </figure>

    <itemizedlist>
      <listitem>
        <para>
          (1) To enable or disable the refresh feature.
        </para>
      </listitem>
      <listitem>
        <para>
          (2) To specify the refresh interval.
        </para>
      </listitem>
      <listitem>
        <para>
          (3) To enable or disable data set invalidation when the data is outdated.
        </para>
      </listitem>
    </itemizedlist>

    <para>
      The data set refresh policy is tightly related to data set caching, detailed in previous section. This invalidation mechanism determines the cache life-cycle.
    </para>

    <para>
      Depending on the nature of the data there exist three main use cases:
    </para>

    <itemizedlist>
      <listitem>
        <para>
          <emphasis role="bold">Source data changes predictable</emphasis> - Imagine a database being updated every night. In that case, the suggested configuration is to use a
          "refresh interval = 1 day" and disable "refresh on stale data". That way, the system will always invalidate the cached data set every day. This is the right configuration
          when we know in advance that the data is going to change.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Source data changes unpredictable</emphasis> - On the other hand, if we do not know whether the database is updated every day, the suggested
          configuration is to use a "refresh interval = 1 day" and enable "refresh on stale data". If so the system, before invalidating any data, will check for modifications.
          On data modifications, the system will invalidate the current stale data set so that the cache is populated with fresh data on the next data set lookup call.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Real time scenarios</emphasis> - In real time scenarios caching makes no sense as data is going to be updated constantly. In this kind of scenarios
          the data sent to the client has to be constantly updated, so rather than enabling the refresh settings (remember this settings affect the caching, and caching is not enabled)
          it's up to the clients consuming the data set to decide when to refresh. When the client is a dashboard then it's just a matter of modifying the refresh settings in the
          Displayer Editor configuration screen and set a proper refresh period, "refresh interval = 1 second" for example.
        </para>
      </listitem>
    </itemizedlist>
  </section>

</section>
